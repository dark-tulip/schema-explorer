# Kafka Connector:

## 0. Какие источники и приемники поддерживаются?

```
ActiveMQ Sink Connector
ActiveMQ Source Connector
Amazon CloudWatch Logs Source Connector
Amazon CloudWatch Metrics Sink Connector
Amazon Kinesis Source Connector
Amazon S3 Sink Connector
Amazon S3 Source Connector
Amazon SQS Source Connector
Apache HBase Sink Connector
Appdynamics Metrics Sink Connector
AWS DynamoDB Sink Connector
AWS Lambda Sink Connector
AWS Redshift Sink Connector
Azure Blob Storage Sink Connector
Azure Blob Storage Source Connector
Azure Cognitive Search Sink Connector
Azure Data Lake Storage Gen1 Sink Connector
Azure Data Lake Storage Gen2 Sink Connector
Azure Event Hubs Source Connector
Azure Functions Sink Connector
Azure Service Bus Source Connector
Azure Synapse Analytics Sink Connector
Cassandra Sink Connector
Databricks Delta Lake Sink Connector
Data Diode Connector (Source and Sink)
Datadog Metrics Sink Connector
Datagen Source Connector (Development Testing)
Elasticsearch Sink Connector
GitHub Source Connector
Google BigQuery Sink Connector
Google Cloud BigTable Sink Connector
Google Cloud Dataproc Sink Connector
Google Cloud Functions Sink Connector
Google Cloud Pub/Sub Source Connector
Google Cloud Spanner Sink Connector
Google Cloud Storage Sink Connector
Google Cloud Storage Source Connector
Google Firebase Connector
HEAVY-AI (formerly OmniSci) Sink Connector
HDFS 2 Sink Connector
HDFS 2 Source Connector
HDFS 3 Sink Connector
HDFS 3 Source Connector
HTTP Sink Connector
HTTP Source Connector
IBM MQ Source Connector
IBM MQ Sink Connector
InfluxDB Connector (Source and Sink)
JDBC Connector (Source and Sink)
JMS Sink Connector
JMS Source Connector
Kudu Connector (Source and Sink)
MapR DB Sink Connector
Microsoft SQL Server Source Connector (Deprecated)
MongoDB Source Connector (Debezium)
MQTT Connector (Source and Sink)
MySQL Source Connector (Debezium)
Netezza Sink Connector
Oracle CDC Source Connector
Pagerduty Sink Connector
PostgresSQL Source Connector (Debezium)
RabbitMQ Sink Connector
RabbitMQ Source Connector
Redis Sink Connector
Salesforce Bulk API Source Connector
Salesforce Change Data Capture Source Connector
Salesforce Connector (Source and Sink)
ServiceNow Connector (Source and Sink)
SFTP Connector (Source and Sink)
SNMP Trap Source Connector
Solace (Source and Sink)
Splunk Sink Connector
Splunk Source Connector
Splunk S2S Source Connector
Spool Dir Connector
SQL Server Source Connector (Debezium)
Syslog Source Connector
Teradata Connector (Source and Sink)
TIBCO Sink Connector
TIBCO Source Connector
Vertica Sink Connector
VMware Tanzu Gemfire Sink Connector
Zendesk Source Connector
```

## 1. Какое API предоставляет система?

#### Требуется описать основные функциональные возможности (копирование, репликация и тп). Описать основные параметры операций (частота репликации и тп). Приложить ссылки на документацию и описание функционала.

Каждый коннектор имеет свои уникальные параметры настройки, как конфигурация источника данных (например, настройки подключения к базе данных) или целевой системы (например, настройки конечной точки для данных)

**API:**

- Конфигурация каждого коннектора подробно описана в документации. `JDBC Source Connector Configuration` для импорта данных из реляционных баз данных
- Kafka Connect REST API позволяет управлять состоянием и конфигурациями коннекторов, их задач и потоками.

**Частота репликации:**

В Kafka Connect понятие "частота репликации" напрямую не используется. Это зависит от типа коннектора и его конфигурации.

**Частота репликации для источников данных (source connectors):**
- Коннекторы для источников, как JDBC Source Connector. Параметр `poll.interval.ms` определяет, как часто коннектор будет опрашивать источник данных на наличие новых данных. default 5000 миллисекунд (5 секунд).

**Частота репликации для целевых систем (sink connectors):**
- Коннекторы для конечных систем (sink connectors), работают в режиме "стриминга", забирая данные из Kafka и записывая их в целевую систему. Частота репликации больше зависит от скорости обработки данных и от параметров производительности, чем от настраиваемого интервала. Что влияет:
- `poll.interval.ms`
- `batch.size` (размер партии данных для чтения или записи)

_Если речь идет о фактической репликации сообщений в кластере Kafka (между брокерами), то это регулируется настройками самого Kafka, а не Kafka Connect, (replication.factor, min.insync.replicas)._

## 4. Как решается технологическая задача?
#### Используются ли триггеры, журналы транзакций, лог-снифинг, или иные подходы?

Kafka Connect поддерживает несколько методов интеграции данных в зависимости от особенностей источника:

- **CDC** (лог-снифинг) с использованием журналов транзакций — самый популярный. Отслеживание всех изменений в базе данных с минимальным вмешательством в работу приложения. Реальная синхронизация данных, практически в режиме реального времени
- **Триггеры** — не всегда оптимальны для производительности. Для захвата изменений в БД на уровне SQL. Снижают скорость обработки транзакций. Используют если БД не поддерживает CDC или журналы транзакций
- **Polling** (опрос) — неэффективен для больших данных, используется, когда подходы выше невозможны. Есть вероятность потери данных
- **API** и событийная модель — хороший вариант для интеграции с системами, использующими REST API или стриминг

## 6. Дизайн системы.

#### Описанием системы, её ключевых компонентов. Какая у каждого компонента ответственность, и как они взаимодействуют друг с другом?

зачем придумали https://www.confluent.io/blog/event-streaming-platform-1/

- **Connectors**: абстракция высокого уровня, которая координирует потоковую передачу данных путем управления задачами.
- **Tasks**: Реализация копирования данных в Kafka и из нее.
- **Workers**: запущенные процессы, которые выполняют коннекторы и задачи.
- **Converters** : код, используемый для преобразования данных между Connect и системой, отправляющей или получающей данные
- **Transformations**: простая логика для изменения каждого сообщения, созданного или отправленного коннектору.
- **Dead letters queue**: как Connect обрабатывает ошибки коннектора

`[Source] -> [Source Connector] -> [Kafka] -> [Sink Connector] -> [Target]`

**Основные компоненты Kafka Connect:**
- Коннекторы (Connectors) реализует логику подключения к внешней системе. Существуют два типа коннекторов:
    - **Source Connectors:** Коннекторы источников данных. Они извлекают данные из внешних систем и записывают их в топики Kafka.
    - **Sink Connectors:** Коннекторы назначения. Они забирают данные из топиков Kafka и отправляют их во внешние системы.

- Рабочие узлы (Workers) запускают коннекторы и распределяют задачи между собой в зависимости от режима работы:
    - **Standalone Mode:** запускаются в одном рабочем узле
    - **Distributed Mode:**

- **Задачи (Tasks)** отдельные процессы, выполняют работу коннекторов. Каждый коннектор может быть разбит на несколько задач для параллельной обработки. Если источник данных имеет множество партиций, каждая задача может работать с отдельной партицией.

- **Конфигурации коннекторов** определяет, как должен работать коннектор. Конфигурация может включать параметры подключения к БД, частоту опроса данных, схему данных, настройки безопасности и другие важные параметры. передаются при создании коннектора. Kafka Connect автоматически применяет конфигурации к рабочим узлам и задачам.

- **Offset Management** (Управление смещениями) автоматически управляет смещениями (offsets) для каждого коннектора и задачи. Offset Management регулирует, где процесс чтения или записи данных остановился, чтобы в случае перезапуска система могла продолжить с того же места.

- **Топики Kafka для хранения метаданных** В распределенном режиме Kafka Connect использует несколько системных топиков Kafka для управления метаданными и координацией работы:
    - `connect-configs`
    - `connect-offsets`
    - `connect-statuses`

- **REST API** интерфейс для управления коннекторами, рабочими узлами и задачами. Через API можно запускать коннекторы, обновлять их конфигурации, проверять состояние и получать статистику. Для управления и мониторинга системы.

#### Взаимодействие между компонентами:
- **Коннекторы** извлекают или записывают данные
- **Рабочие узлы** взаимодействуют с топиками Kafka, передавая данные в Kafka или получая данные из Kafka для их последующей передачи в целевую систему.
- **Offset Management** контролирует прогресс выполнения задач, чтобы избежать дублирования данных и потери прогресса при сбоях.
- **REST API** предоставляет интерфейс для конфигурации коннекторов, мониторинга и управления ими.
- **Системные Топики Kafka** для хранения метаданных используются в распределенном режиме для координации работы коннекторов, обеспечения согласованности и отказоустойчивости.

Подробнее:
- https://docs.confluent.io/platform/current/connect/design.html
- https://docs.confluent.io/platform/current/connect/index.html#what-is-kafka-connect

## 8. Какие форматы данных используются для передачи изменений?

- Для высокопроизводительных систем бинарные форматы (Avro, Protobuf)
- JSON часто выбирается из-за его удобства в разработке и отладки, особенно на ранних этапах или для небольших объемов данных.
- Эволюция схем: `Avro` и `Protobuf` популярны в системах, где важно поддерживать версионирование данных и гибкость при изменении структуры.

#### Есть ли поддержка гибридных форматов?

С помощью преобразований (**Transformations**): Kafka Connect  поддерживает преобразования данных в потоке с помощью **Single Message Transformations (SMT)**. SMT можно использовать для изменения структуры данных на лету, например, преобразования JSON в XML. Kafka Connect можно настроить:

- Источник данных (Source Connector) будет забирать данные в формате JSON и передавать их в Kafka.
```json
"connector.class": "FileStreamSourceConnector",
"value.converter": "org.apache.kafka.connect.json.JsonConverter",
"value.converter.schemas.enable": "false",
```
- В промежутке можно применить SMT для преобразования данных в XML.
```json
"transforms": "jsonToXml",
"transforms.jsonToXml.type": "com.example.JsonToXmlTransformation",
```
- Приемник данных (Sink Connector) будет получать данные в формате XML и записывать их в конечную систему.
```json
"connector.class": "FileStreamSinkConnector",
"value.converter": "org.apache.kafka.connect.storage.StringConverter",
```
#### Есть ли поддержка сжатия данных?
- Gzip
- Snappy разработан Google. Обеспечивает баланс между скоростью и степенью сжатия.
- LZ4: Очень быстрый алгоритм сжатия, который подходит для высокоскоростных потоков данных.
- Zstd: Новый формат сжатия, обеспечивает лучшее сжатие по сравнению с Gzip и Snappy.

#### Почему выбран тот или иной формат?

По умолчанию Confluent Platform предоставляет следующие конвертеры:

- **AvroConverter**: с Schema Registry
- **ProtobufConverter** с Schema Registry
- **JsonSchemaConverter**  использовать с реестром схем
- **JsonConverter** (без Schema Registry) со структурированными данными
- **StringConverter** простой формат строки
- **ByteArrayConverter** предоставляет опцию «сквозного» преобразования, которая не выполняет преобразование

## 9. Технологический стек компонентов.
#### Какие языки программирования и платформы используются для ключевых компонентов системы? Были ли особенности выбора этих технологий (производительность, совместимость, масштабируемость)?

**написан на Java, как и сама Apache Kafka**
- Производительность JVM и возможностей многопоточности были важным фактором при выборе технологий.
- Экосистема: Большая экосистема библиотек и фреймворков для работы с сетевыми операциями, асинхронными вычислениями и данными, что делает Java идеальным кандидатом для построения распределенных систем.
- Кроссплатформенность: Kafka и Kafka Connect могут работать на разных платформах благодаря JVM.

**Scala:**

- Хотя Kafka Connect в основном написан на Java, некоторая часть экосистемы Kafka написана на Scala (особенно ранние версии Kafka).
- Scala поддерживает функциональное программирование, что облегчает работу с потоками данных и реактивными системами.

**Python:**
- В экосистеме Kafka существуют инструменты и коннекторы, написанные на Python. пользователи могут писать собственные коннекторы и Single Message Transforms на Python для простоты разработки.
- Простота и удобство разработки, быстрая разработка прототипов.
- Широкая поддержка библиотек для обработки данных.

#### Платформы
- **ApacheKafka** тесно интегрирован, отвечает за передачу сообщений и управление топиками
- **Zookeeper** централизованное управление конфигурацией. Ранние версии Kafka полагались на Zookeeper для управления кластером, включая хранение метаданных и координацию работы брокеров.
- **REST API** Возможность управлять и отслеживать состояние коннекторов через HTTP-запросы.
- **Confluent Schema Registry**
    - Для работы с Avro или Protobuf
    - обеспечивает управление схемами и их эволюцию.
    - Управление совместимостью схем при работе с бинарными форматами данных.
    - предотвращение ошибок, связанных с несовместимостью схем.

## 10. Масштабируемость и производительность. Как система справляется с большими объемами данных?

#### Какие механизмы для горизонтального и вертикального масштабирования предусмотрены? В каких случаях система начинает плохо справляться и почему?

Масштабируемость и производительность Kafka Connect
- поддерживает как горизонтальное, так и вертикальное масштабирование.
- способна обрабатывать огромные потоки данных в реальном времени

#### 1. Горизонтальное масштабирование
- поддерживает распределённую архитектуру
- легко масштабируется горизонтально (включает добавление новых узлов в кластер Kafka Connect)

**механизмы горизонтального масштабирования:**
- **Кластерная архитектура:** позволяет добавлять новые узлы по мере увеличения нагрузки. Каждый новый узел может выполнять один или несколько коннекторов, увеличивая общую пропускную способность системы.

- **Шардирование:** Разделение данных на шардированные сегменты позволяет равномерно распределять обработку данных между коннекторами.

- **Динамическое перераспределение коннекторов:** Если один узел выходит из строя или перегружается, задачи коннекторов автоматически перераспределяются между другими узлами в кластере. Это помогает избежать простоев и позволяет системе оставаться устойчивой при сбоях.

**Коннекторы с разделением данных:** Многие коннекторы поддерживают разделение данных на несколько потоков (например, чтение из нескольких таблиц или файлов одновременно).

#### 2. Вертикальное масштабирование:
- связано с улучшением производительности каждого узла кластера за счёт увеличения его вычислительных ресурсов (CPU, память, дисковая подсистема)

**механизмы вертикального масштабирования:**
- Оптимизация JVM: Так как Kafka Connect работает на JVM, возможно улучшение производительности через тюнинг параметров JVM (например, управление памятью и сборкой мусора).
- Использование быстрых хранилищ данных: Для эффективной обработки больших объёмов данных Kafka Connect может использовать современные хранилища с низкой латентностью, такие как NVMe-диски и SSD, для временного хранения данных.
- Оптимизация коннекторов: Некоторые коннекторы могут быть ресурсоёмкими, поэтому их оптимизация или использование высокопроизводительных версий коннекторов (например, кастомных решений) позволяет увеличить производительность узла.

#### 3. Механизмы производительности и обработки больших объёмов данных:
- **Конвейерная обработка данных:** позволяет передавать большие объёмы данных с минимальной задержкой. Коннекторы работают асинхронно, не блокируя основной поток данных.

- **Буферизация:** использует внутренние механизмы буферизации для увеличения пропускной способности. Данные могут временно храниться в памяти, прежде чем быть обработаны и отправлены в конечные системы.

- **Поддержка компрессии данных:** полезно при передаче больших объёмов данных с минимальными затратами на сетевые ресурсы

#### 4. Когда система начинает плохо справляться:
Несмотря на свою гибкость и масштабируемость, Kafka Connect может испытывать проблемы в некоторых сценариях, особенно при неверной конфигурации или экстремальных нагрузках:

Основные причины проблем:
- Неправильная настройка JVM: недостаточная память или неправильная настройка (GC) могут привести к проблемам с производительностью и сбоям в работе.
- Слишком высокая нагрузка на один узел: (много коннекторов или сложные операции преобразования данных), узел может быть перегружен.
- Медленные хранилища данных: медленные внешние системы, например БД
- Ограниченные сетевые ресурсы: если объем данных очень велик и данные передаются между различными географическими зонами.
- Неверная конфигурация Kafka: Kafka Connect сильно зависит от конфигурации самого кластера Kafka. Например, если настроено слишком малое количество разделов (partitions) или недостаточное количество реплик, производительность системы может снижаться из-за задержек и конфликтов при доступе к данным.

#### 5. Оптимизация производительности:
- Тюнинг параметров Kafka: Увеличение количества разделов (partitions) и корректная настройка параметров Kafka, таких как `fetch.min.bytes`, `replica.lag.time.max.ms` и `linger.ms`, может помочь повысить пропускную способность.
- Тюнинг коннекторов
- Распределение нагрузки
- Параллелизация задач

## 11. Как технологически система справляется с изменениями в схеме данных (например, добавление/удаление полей)?

Kafka Connect предоставляет несколько механизмов для обработки изменений в схеме данных:

- Schema Registry и поддержка версий схем;
- SMT для динамических преобразований данных;
- Автоматическое управление версиями и проверка совместимости для обеспечения стабильной работы системы.

#### Schema Registry
Kafka Connect использует систему, где изменения в схеме данных автоматически регистрируются и проверяются на совместимость при помощи Schema Registry. Вот как это происходит:

- Добавление полей: Если в схему данных добавляется новое поле, и оно является необязательным или имеет значение по умолчанию, это не нарушает работу системы. В таких случаях изменения считаются совместимыми, и Kafka Connect продолжает обрабатывать данные.

- Удаление полей: Удаление поля из схемы может создать проблемы, особенно если потребители данных ожидают его наличия. В этом случае важно поддерживать бэквардную совместимость, чтобы потребители могли обрабатывать записи с "устаревшими" полями.

- Изменение типа поля: Изменение типа поля (например, из строки в целое число) может быть несовместимым, и система выдаст ошибку при проверке совместимости через Schema Registry. Для решения таких проблем могут быть использованы механизмы миграции данных.

#### Пример возможных SMT трансформаций:

- AddField: Добавление нового поля в сообщение.
- ReplaceField: Замена полей в сообщениях.
- Cast: Приведение типов данных для соответствия новой схеме.

## 12. Есть ли возможность пользователям самим добавлять источники и таргеты, как реализована эта функциональность?
#### Ответ на это вопрос может помочь нам начать масштабироваться по источникам и таргетам.

Kafka Connect предоставляет пользователям возможность легко добавлять источники (sources) и приемники данных (targets) без необходимости вносить изменения в ядро системы. Эта функциональность реализована через модульную архитектуру коннекторов:

**1. Коннекторы (Connectors)**

- Source Connectors — используются для подключения к источникам данных (базы данных, REST API, файловые системы и др.) и передачи данных в Kafka.
- Sink Connectors — используются для передачи данных из Kafka в целевые системы (хранилища данных, базы данных, системы аналитики и др.).

**2. Добавление коннекторов**
Пользователи могут легко добавлять новые источники и цели данных через интерфейсы Kafka Connect, что делает систему высоко масштабируемой и гибкой:

- Конфигурационные файлы: Чтобы подключить новый источник или приемник, пользователь указывает параметры коннектора (например, URL базы данных, учетные данные, форматы данных и т.д.) в виде конфигурационного файла JSON. Эта конфигурация затем отправляется в Kafka Connect, который динамически загружает и запускает коннектор.
- REST API: Kafka Connect предоставляет REST API, через которое можно программно управлять коннекторами. Пользователи могут добавлять, обновлять и удалять коннекторы с помощью простых HTTP-запросов. Пример REST-запроса для создания нового коннектора:

```bash
POST /connectors
{
  "name": "my-source-connector",
  "config": {
    "connector.class": "com.example.MySourceConnector",
    "tasks.max": "1",
    "topics": "my-topic",
    ...
  }
}
```

**3. Модульность и поддержка сторонних коннекторов**
- позволяет пользователям устанавливать новые коннекторы, разработанные как сообществом, так и сторонними разработчиками.
- **Коннекторы могут загружаться динамически без необходимости остановки** Kafka Connect.
- Каталог коннекторов: Существует множество готовых коннекторов в официальном и стороннем каталоге Confluent Hub, откуда пользователи могут загружать и устанавливать их.
- Разработка собственных коннекторов: Пользователи могут создавать свои коннекторы используя предоставленный Kafka Connect API.

## 13. Вопрос на будущее.

#### Как встраивается обработка потока данных, аналитика над ним? Какие технологии для обработки и аналитики доступны?

- реализованы с помощью дополнительных компонентов, таких как Kafka Streams, ksqlDB

#### 1. Kafka Streams
Kafka Streams — это встроенная библиотека для обработки потоков данных, которая позволяет обрабатывать сообщения прямо в Kafka.

- Stateful и stateless операции: как простые операции (фильтрация, маппинг), так и сложные операции с состоянием (например, агрегации с сохранением состояния).
- Функции окон (windowing): для аналитики по временным интервалам.
- Горизонтальное масштабирование: могут быть распределены между множеством экземпляров для обработки больших объемов данных
- Kafka Streams работает непосредственно с Kafka без необходимости установки дополнительных систем.

```java
KStream<String, String> stream = builder.stream("input-topic");
KStream<String, String> transformedStream = stream
    .filter((key, value) -> value.length() > 5)
    .mapValues(value -> value.toUpperCase());
transformedStream.to("output-topic");
```
#### 2. ksqlDB
- SQL-платформа для потоковой обработки данных, построенная поверх Kafka Streams.
- позволяет выполнять аналитические запросы на данных, проходящих через Kafka, с использованием  SQL-синтаксиса
- ksqlDB позволяет сохранять промежуточные результаты и состояния
- все можно реализовать через SQL-запросы.
  Пример запроса в ksqlDB для создания потоковой агрегации:

```sql
CREATE STREAM pageviews_per_region AS
SELECT regionid, COUNT(*) AS view_count
FROM pageviews
WINDOW TUMBLING (SIZE 5 MINUTES)
GROUP BY regionid;
```

