# airbyte
0. Источники и приемники
Airbyte: базы данных (реляционные,  нереляционные), различные api, различные S3, так же можно загружать просто файлы, брокеры сообщений. PostgreSQL, MySQL, MSSQL, MongoDB, Oracle - базы данных; Shopify, Stripe, Salesforce, Reddit, Twitter - api; S3 - AWS S3, Google Cloud Storage, Kafka, Redis. В общем, все более менее популярное поддерживается. 
1. API 
Документация aitbyte: https://docs.airbyte.com/using-airbyte/getting-started/
Функциональные возможности airbyte.
- Создать / удалить источник / приемник / соединения
- Запуск / остановка копирования / репликации
- Получить статус / мониторинги / логи операции / источников / приемников
- Алертинг
- Можно обновлять конфигурации на ходу
- Кастомное управление коннекторами 
Параметры операций:
* Частота синхронизации (репликации)
* Режими репликации - полный или инкрементальный. Полный - репликация всех данных, инкрементальный - репликация только новых данных в иcточнике. 
* DBT трансформации уже после загрузки данных.
* Параметры пачки данных для трансфера (размер, количество записей и тп). 
* Настройка работы при ошибках - сетевых, внутренних. 
* Шифрование данных. 
* Управление схемой данных. 
2. Технологическое решение. 
Airbyte: Принципильно во может быть всего два подхода со стороны cdc. Это - полинг или пушинг, то есть ли бы у кого-то забираем данные (как например сканинг журнала транзакций) или нас кто-то кормит данными (например тригеры). Airbyte выбирает свой подход для каждого источника. Из основных это сканинг журнала транзакций и использование встроенных в СУБД тригеров.  Это наталкивает на мысли, что существует два типа core части для задачи data-transfer'a. 
3. Архитектура: 
Документация: https://docs.airbyte.com/understanding-airbyte/high-level-view
![airbyte](airbyte.png)
Основные компоненты:
- UI - клиентский веб-интерфейс
- Server - логика по обработку клиента и делегировани его задач дальше. 
- Configs & jobs - база данных с конфигами обработок, кредами к базам данных и тому подобным
- Scheduler - планировщик обработок
- Worker - тот кто выполняет клиентские обработки
- Workload - управляющий элемент конкретной обработки 
Остальные компоненты представлют из себя технические детали.
4. Форматы данных
Airbyte: предлагает использовать свою типизацию данных, это ему позволяет использовать любой транспорт данных. На деле он использует сериализованный json своего формата. C возможными типами данных можно ознакомиться ниже
https://docs.airbyte.com/understanding-airbyte/supported-data-types
5. Технологический стек
Airbyte Guthub: https://github.com/airbytehq/airbyte
Основные языки core части - java, kotlin. 
Для коннекторов можно использовать, что угодно, большая часть коннекторов написана на python. 
6. Узкие места:
Airbyte создан, чтобы хорошо справляться с большими объемами данных, поэтому тут ограничений нет. Задержка данных уменьшается за счет увеличения частоты репликации, а следовательно повышение стоимости обслуживания. 
В сообществе встречается множество бенчмарков, где airbyte показывает себя медленнее других cdc систем. 
7. Изменения в схеме данных
Airbyte поддерживает изменение схемы. Как я понял airbyte обновляет схему с помощью полной остановки системы, но это не точно. 
8.  Новые коннекторы:
Airbyte: Да, новые источники и таргеты можно поддержать c помощью написания к ним коннекторов. Главные предпосылки к возможности раширения - это:
   - Модельная архитектура, выделение конекторов в отдельные компоненты 
   - Типизация данных
9. Трансформация данных:
Airbyte напрямую не поддерживает ETL-подход трансформаций или аналитики данных на лету, главных ELT-подход, примером служит DBT (data builder tool). Однако ничего не мешает сделать эту обработку при написании своих коннекторов.  
# aws migration system
0. Источники и приемники
Источники: **Базы данных**: MySQL, PostgreSQL, Oracle, Microsoft SQL Server и другие. **Виртуальные машины**: VMware, Hyper-V, Azure, Google Cloud. **Локальные данные**: данные с локальных серверов и хранилищ.
Приемники: **AWS**: RDS (для разных движков), Redshift, S3, EC2 и другие. **On-premises** и **другие облака** (в некоторых случаях)
1. API
Документация aws migration system: https://docs.aws.amazon.com/mgn/
API AWS Migration System предоставляет интерфейс для управления миграциями данных и приложений. Он позволяет инициировать, управлять и отслеживать миграционные процессы. Включает функции для создания и настройки миграционных задач, мониторинга их состояния, просмотра логов, настройки источников и целевых систем, автоматизации процессов переноса с минимальным простоем и возможностью масштабирования. Поддерживает разные типы источников и приемников данных, позволяет управлять разрешениями и ролями, а также интегрироваться с другими AWS сервисами для обеспечения безопасности и стабильности процесса миграции.
Принципиально все тоже самое, но дополнительно ещё есть сервис миграции серверов и приложений.
2. Технологическое решение. 
3. Архитектура: 
AWS migration system: нет исходного кода, нет описания.
4. Формат данных 
AWS migration system: нет описания форматов данных. Судя по документации так же присутствует типизация данных: https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Reference.DataTypes.html
5. Технологический стек
Не опенсорс решение, поэтому информации нет.
6. Где справляется хорошо? Где справляется плохо?
AWS Migration справляется хорошо с переносом приложений и данных в облако, особенно когда нужны высокая скорость миграции и поддержка большого числа источников и целевых сервисов. Он отлично интегрируется с другими AWS сервисами, обеспечивает автоматизацию процессов и минимальные простои, что делает его удобным для компаний, уже работающих в экосистеме AWS. Однако он может быть менее эффективен для гибридных сред, где требуется поддержка локальных систем вне AWS. Кроме того, сложные сценарии миграции данных из других облаков могут потребовать дополнительных настроек и инструментов, а стоимость может быстро возрасти при масштабировании миграционных процессов.
7. Изменения схемы данных
AWS migration system не подерживает изменение схемы в автоматическом режиме, только в ручном = остановли, обновили, запустили.
8. AWS migration system: нет возможности писать свои коннекторы.
9. Трансформации данных
AWS migration system: предлагется использовать API AWS DMS поддерживает ETL подход на крйне ограниченном наборе возможных трансформаций.
# IBM InfoSphere 
0. Источники и приемники
Источники **Базы данных**: Oracle, DB2, SQL Server, Informix, Teradata, и другие. **Файловые хранилища**: XML, JSON, CSV, и текстовые файлы. **Приложения**: SAP, Siebel, PeopleSoft.
Приемники: **Базы данных**: DB2, Oracle, SQL Server, Netezza и другие. **Хранилища данных**: Hadoop, IBM Cloud, AWS S3, Azure. **Приложения** и **ETL-системы**
1. API 
Документация infoSphere: https://www.ibm.com/support/pages/infosphere-information-server-version-113-product-documentatio
API IBM InfoSphere предоставляет интерфейс для управления интеграцией, качеством и миграцией данных. Он позволяет подключаться к источникам данных, трансформировать их, управлять потоками данных, отслеживать и автоматизировать процессы интеграции. API обеспечивает доступ к функциям настройки и запуска ETL-процессов, мониторинга качества данных, управления метаданными и построения мастер-данных. Интеграция с различными источниками, включая базы данных, файловые системы и корпоративные приложения, поддерживает высокую производительность и масштабируемость, обеспечивая безопасное и надежное перемещение данных между системами.
2. Технологическое решение. 
3. Архитектура: 
InfoSphere: нет исходного кода, нет описания.
4. Формат данных 
На просторах интренета нашел, что используется свой кастомный бинарный протокол. 
5. Технологический стек
Не опенсорс решение, поэтому информации нет.
6. Где справляется хорошо? Где справляется плохо?
IBM InfoSphere отлично справляется с обработкой больших объемов корпоративных данных, обеспечивая высокую скорость интеграции и надежность для сложных ETL-процессов. Он хорошо подходит для обеспечения качества данных и работы с мастер-данными, легко масштабируется в крупных организациях, поддерживая комплексные требования к безопасности и соответствию. Однако InfoSphere может быть сложным и затратным в настройке, особенно для небольших компаний или более простых задач интеграции. Кроме того, его закрытая экосистема ограничивает гибкость в сравнении с некоторыми опенсорсными решениями, а также может потребовать высоких затрат на лицензии и техническое сопровождение.
7. Cхема данных
Аналогично AWS - подержки автоматического изменения нету.  
8. Кастомные коннекторы:
В IBM InfoSphere можно писать свои коннекторы. Платформа предоставляет API и инструменты для разработки кастомных коннекторов, что позволяет интегрировать нестандартные источники данных и адаптировать процессы под специфические бизнес-требования.
9. Трансформации данных 
В IBM InfoSphere можно писать кастомные трансформации данных. Платформа предоставляет инструменты для создания пользовательских преобразований, которые позволяют адаптировать обработку данных под специфические требования и бизнес-логики.
